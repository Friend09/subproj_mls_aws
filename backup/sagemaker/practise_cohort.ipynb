{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b7ba7b-433c-463c-8e5e-8b975a5be463",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building Machine Learning Systems That Don't Suck\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7bb73f",
   "metadata": {},
   "source": [
    "This notebook creates a [SageMaker Pipeline](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html) to build an end-to-end Machine Learning system to solve the problem of classifying penguin species. With a SageMaker Pipeline, you can create, automate, and manage end-to-end Machine Learning workflows at scale.\n",
    "\n",
    "You can find more information about Amazon SageMaker in the [Amazon SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html). The [AWS Machine Learning Blog](https://aws.amazon.com/blogs/machine-learning/) is an excellent source to stay up-to-date with SageMaker.\n",
    "\n",
    "This example uses the [Penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data).\n",
    "\n",
    "<img src='images/penguins.png' alt='Penguins' width=\"800\">\n",
    "\n",
    "This notebook is part of the [Machine Learning School](https://www.ml.school) program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec22ac1",
   "metadata": {},
   "source": [
    "## Session 1 - Introduction and Initial Setup\n",
    "\n",
    "The machine learning system we'll build during this program consists of four main pipelines: A **training** pipeline, an **inference** pipeline, a **deployment** pipeline, and a **monitoring** pipeline.\n",
    "\n",
    "Here is an architectural diagram showing how the system is structured:\n",
    "\n",
    "<a href=\"images/diagram.png\" target=\"_blank\"> <img src=\"images/diagram.png\" alt=\"SageMaker architectural diagram of the system\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Throughout the sessions, we'll build each of these pipelines. We'll also build variations to show you different alternatives and best practices.\n",
    "\n",
    "Let's start by setting up the environment and preparing to run the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2265b0",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "588d34c9",
   "metadata": {},
   "source": [
    "We can run this notebook in [Local Mode](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-local-mode.html) to test some of the system components in your local environment. Unfortunately, not every component is supported in Local Mode.\n",
    "\n",
    "Setting the `LOCAL_MODE` variable to `True` will run every supported pipeline component locally. Setting the variable to `False` will run the pipeline in SageMaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c4d764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6be4f8d",
   "metadata": {},
   "source": [
    "Let's now load the environment variables we need to run the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3164a3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa700f4",
   "metadata": {},
   "source": [
    "If you are running the pipeline in Local Mode on an ARM64 machine (for example, on Apple Silicon), you will need to use a custom Docker image to train and evaluate the model. Let's create a variable indicating if we are running on an ARM64 machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc40d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d906ada",
   "metadata": {},
   "source": [
    "Let's create a configuration dictionary with different settings depending on whether we are running the pipeline in Local Mode. We'll use this dictionary to configure the pipeline components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3f17e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9089696b",
   "metadata": {},
   "source": [
    "Let's now initialize a few variables that we'll need throughout the notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942a01b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a835695-557b-46d8-a901-a29bc57df5fe",
   "metadata": {},
   "source": [
    "## Session 2 - Exploratory Data Analysis\n",
    "\n",
    "Let's run Exploratory Data Analysis on the [Penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data). The goal of this session is to understand the data and the problem we are trying to solve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6943b",
   "metadata": {},
   "source": [
    "Let's load the Penguins dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cd2f0e-446d-48a9-a008-b4f1cc593bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9eae10e-20c4-477e-b6b8-965c3a53566e",
   "metadata": {},
   "source": [
    "We can see the dataset contains the following columns:\n",
    "\n",
    "1. `species`: The species of a penguin. This is the column we want to predict.\n",
    "2. `island`: The island where the penguin was found\n",
    "3. `culmen_length_mm`: The length of the penguin's culmen (bill) in millimeters\n",
    "4. `culmen_depth_mm`: The depth of the penguin's culmen in millimeters\n",
    "5. `flipper_length_mm`: The length of the penguin's flipper in millimeters\n",
    "6. `body_mass_g`: The body mass of the penguin in grams\n",
    "7. `sex`: The sex of the penguin\n",
    "\n",
    "If you are curious, here is the description of a penguin's culmen:\n",
    "\n",
    "<img src='images/culmen.jpeg' alt='Culmen' width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544bc0c3",
   "metadata": {},
   "source": [
    "Now, let's get the summary statistics for the features in our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2107c25-e730-4e22-a1b8-5bda53e61124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e19af7-9f0f-45fe-b7d3-f19721c02a2b",
   "metadata": {},
   "source": [
    "Let's now display the distribution of values for the three categorical columns in our data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1242122a-726e-4c37-a718-dd8e873d1612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d98fdd-3b8c-40a2-b8dc-15162b4049e2",
   "metadata": {},
   "source": [
    "The distribution of the categories in our data are:\n",
    "\n",
    "-   `species`: There are 3 species of penguins in the dataset: Adelie (`152`), Gentoo (`124`), and Chinstrap (`68`).\n",
    "-   `island`: Penguins are from 3 islands: Biscoe (`168`), Dream (`124`), and Torgersen (`52`).\n",
    "-   `sex`: We have `168` male penguins, `165` female penguins, and `1` penguin with an ambiguous gender (`.`).\n",
    "\n",
    "Let's replace the ambiguous value in the `sex` column with a `null` value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1cf582-8831-4f83-bb17-2175afb193e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8425ce-ce4e-43e6-9ed8-0398b780cc66",
   "metadata": {},
   "source": [
    "Next, let's check for any missing values in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc42cb08-275c-4b05-9d2b-77052da2f336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b65207c-3e66-453a-87a1-751636c979ee",
   "metadata": {},
   "source": [
    "Let's get rid of the missing values. For now, we are going to replace the missing values with the most frequent value in the column. Later, we'll use a different strategy to replace missing numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c57d55d-afd6-467a-a7a8-ff04132770ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5758214f-a4ab-4980-8892-91ec8d218ef3",
   "metadata": {},
   "source": [
    "Let's visualize the distribution of categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2852c740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b04c8fae-35b4-4d8e-8fff-decee050af3a",
   "metadata": {},
   "source": [
    "Let's visualize the distribution of numerical columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "707cc972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef241df0-3acd-4401-a2c6-b70723d7595b",
   "metadata": {},
   "source": [
    "Let's display the covariance matrix of the dataset. The \"covariance\" measures how changes in one variable are associated with changes in a second variable. In other words, the covariance measures the degree to which two variables are linearly associated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3daf3ba1-d218-4ad4-b862-af679b91273f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fbbe6bc-0104-4663-8c30-8f9566755739",
   "metadata": {},
   "source": [
    "Here are three examples of what we get from interpreting the covariance matrix below:\n",
    "\n",
    "1. The positive covariance of 50.26 between culmen length and flippler length suggests that larger values of culmen length are associated with larger values of flipper length. As one increases, generally so does the other.\n",
    "2. The positive covariance of 2596.97 between culmen length and body mass suggests that heavier penguins generally have longer culmens. There is a tendency for these two variables to increase together.\n",
    "3. The negative covariance of -742.66 between culmen depth and body mass suggests a general tendency that penguins with deeper culmens weigh less.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81117f",
   "metadata": {},
   "source": [
    "Let's now display the correlation matrix. \"Correlation\" measures both the strength and direction of the linear relationship between two variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d793e09-2cb9-47ff-a0e6-199a0f4fc1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aec4c08-767c-4740-959c-2d76268c3513",
   "metadata": {},
   "source": [
    "Here are three examples of what we get from interpreting the correlation matrix below:\n",
    "\n",
    "1. Penguins that weight more tend to have longer flippers.\n",
    "2. Penguins with a shallower culmen tend to have longer flippers.\n",
    "3. Penguins with longer culmens tend to have longer flippers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fef0cf",
   "metadata": {},
   "source": [
    "Let's display the distribution of species by island:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1258c99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d74ae740-3590-4dce-ac5a-6205975c83da",
   "metadata": {},
   "source": [
    "Let's display the distribution of species by sex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45b0a87f-028d-477f-9b65-199728c0b7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11137928-6b4e-465c-8ad7-2297afbaa33c",
   "metadata": {},
   "source": [
    "## Session 3 - Splitting and Transforming the Data\n",
    "\n",
    "In this session we'll build a simple [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with one step to split and transform the data:\n",
    "\n",
    "<a href=\"images/processing-step.png\" target=\"_blank\"> <img src=\"images/processing-step.png\" alt=\"High-level overview of the Preprocessing Step\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We'll use a [Scikit-Learn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for the transformations, and a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) with a [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#scikit-learn-processor) to execute a preprocessing script. Check the [SageMaker Pipelines Overview](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) for an introduction to the fundamental components of a SageMaker Pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d06e0-b711-4e3d-b424-6fa611a51f94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1 - Creating the Preprocessing Script\n",
    "\n",
    "The first step we need in the pipeline is a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) to run a script that will split and transform the data.\n",
    "\n",
    "This Processing Step will create a SageMaker Processing Job in the background, run the script, and upload the output to S3. You can use Processing Jobs to perform data preprocessing, post-processing, feature engineering, data validation, and model evaluation. Check the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) SageMaker's SDK documentation for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6f546",
   "metadata": {},
   "source": [
    "We will store the script in a folder called `processing` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78fe069e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021b8e0c",
   "metadata": {},
   "source": [
    "Let's now create the script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb6ba7c0-1bd6-4fe5-8b7f-f6cbdfd3846c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39301f9f",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1f122a4-acff-4687-91b9-bfef13567d88",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc3b7a57",
   "metadata": {},
   "source": [
    "### Step 2 - Caching Configuration\n",
    "\n",
    "Several SageMaker Pipeline steps support caching. When a step runs, and dependending on the configured caching policy, SageMaker will try to reuse the result of a previous successful run of the same step. You can find more information about this topic in [Caching Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html).\n",
    "\n",
    "Let's define a caching policy that we'll reuse on every step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d88e9ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "304b3dfc",
   "metadata": {},
   "source": [
    "### Step 3 - Pipeline Configuration\n",
    "\n",
    "We can parameterize a SageMaker Pipeline to make it more flexible. In this case, we'll use a parameter to pass the location of the dataset we want to process. We can execute the pipeline with different datasets by changing the value of this parameter. Check [Pipeline Parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "331fe373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbff9c36",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Processing Step\n",
    "\n",
    "Let's now define the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) that we'll use in the pipeline to run the script that will split and transform the data.\n",
    "\n",
    "A processor gives the Processing Step information about the hardware and software that SageMaker should use to launch a Processing Job. To run the script we created, we need access to Scikit-Learn, so we can use the [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#scikit-learn-processor) processor that comes out-of-the-box with the SageMaker's Python SDK.\n",
    "\n",
    "SageMaker manages the infrastructure of a Processing Job. It provisions resources for the duration of the job, and cleans up when it completes. The Processing Container image that SageMaker uses to run a Processing Job can either be a SageMaker built-in image or a custom image:\n",
    "\n",
    "<a href=\"images/processing-job.png\" target=\"_blank\"> <img src=\"images/processing-job.png\" alt=\"High-level overview of a SageMaker Processing Job\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "The [Data Processing with Framework Processors](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks.html) page discusses other built-in processors you can use. The [Docker Registry Paths and Example Code](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html) page contains information about the available framework versions for each region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aa4471a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf2cc58",
   "metadata": {},
   "source": [
    "Let's now define the Processing Step that we'll use in the pipeline.\n",
    "\n",
    "This step will specify the list of inputs that we'll access from the preprocessing script. In this case, the input is the dataset we stored in S3. We also have a few outputs that we want SageMaker to capture when the Processing Job finishes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdbd9303",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fad062cb",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "We can now create the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e140642a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63c190c5-52b5-4ccc-8d42-847a694b8e66",
   "metadata": {},
   "source": [
    "## Session 4 - Training the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [step to train a model](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training). Check [Train a Model with TensorFlow](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow) for more information about training a model with TensorFlow.\n",
    "\n",
    "<a href=\"images/training-step.png\" target=\"_blank\"> <img src=\"images/training-step.png\" alt=\"High-level overview of the Training Step\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We'll also introduce experiment tracking using [Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) and [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8608092-7aab-4fd2-aa99-47c2db27bdb7",
   "metadata": {},
   "source": [
    "### Step 1 - Creating the Training Script\n",
    "\n",
    "Let's create the training script. This script is responsible for training a neural network using the train data, validating the model, and saving it so we can later use it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e9294",
   "metadata": {},
   "source": [
    "We will store the script in a folder called `training` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac0b891c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c3cec9",
   "metadata": {},
   "source": [
    "We can now create the script inside the folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d92b121d-dcb9-43e8-9ee3-3ececb583e7e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50f0a4fa-ce70-4882-b9f5-8253df03d890",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14ea27ce-c453-4cb0-b309-dbecd732957e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27cff4c1-6510-4d99-8ae1-cb14927b87c7",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up the Training Step\n",
    "\n",
    "We can now create a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) that we can add to the pipeline. This Training Step will create a SageMaker Training Job in the background, run the training script, and upload the output to S3. Check the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "SageMaker manages the infrastructure of a Training Job. It provisions resources for the duration of the job, and cleans up when it completes. The Training Container image that SageMaker uses to run a Training Job can either be a SageMaker built-in image or a custom image.\n",
    "\n",
    "<a href=\"images/training-job.png\" target=\"_blank\"> <img src=\"images/training-job.png\" alt=\"High-level overview of a SageMaker Training Job\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "The [Available Deep Learning Container Images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md) page contains the list of available containers for each region.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d8729",
   "metadata": {},
   "source": [
    "Our training script uses [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github) to track metrics from the Training Job. We need to create a `requirements.txt` file to install the Comet library in the training container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d00eda86",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6857eeb",
   "metadata": {},
   "source": [
    "SageMaker uses the concept of an [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) to handle end-to-end training and deployment tasks. For this example, we will use the built-in [TensorFlow Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to run the training script we wrote before.\n",
    "\n",
    "Notice the list of hyperparameters defined below. SageMaker will pass these hyperparameters as arguments to the entry point of the training script.\n",
    "\n",
    "We are going to use [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github) and [SageMaker Experiments](https://sagemaker.readthedocs.io/en/v2.174.0/experiments/sagemaker.experiments.html) to track metrics from the Training Job. SageMaker Experiments will use the list of metric definitions to decide which metrics to track and how to parse them from the Training Job logs. For more information, check [Manage Machine Learning with Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) and the [SageMaker Experiments' SDK documentation](https://sagemaker.readthedocs.io/en/v2.174.0/experiments/sagemaker.experiments.html).\n",
    "\n",
    "Here are the environment variables we need to set on the traininng container:\n",
    "\n",
    "-   `COMET_API_KEY`: This is your [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github) API key.\n",
    "-   `COMET_PROJECT_NAME`: The name of the project where you want to track the experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90fe82ae-6a2c-4461-bc83-bb52d8871e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "545d2b43-3bb5-4fe9-b3e4-cb8eb55c8a21",
   "metadata": {},
   "source": [
    "We can now create a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training). This Training Step will create a SageMaker Training Job in the background, run the training script, and upload the output to S3. Check the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "This step will receive the train and validation split from the preprocessing step as inputs.\n",
    "\n",
    "Here, we are using three input channels, `train`, `validation`, and `pipeline`. SageMaker will automatically create an environment variable corresponding to each of these channels following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "-   `SM_CHANNEL_TRAIN`: This environment variable will contain the path to the training data coming from the preprocessing step.\n",
    "-   `SM_CHANNEL_VALIDATION`: This environment variable will contain the path to the validation data coming from the preprocessing step.\n",
    "-   `SM_CHANNEL_PIPELINE`: This environment variable will contain the path to the transformation pipeline that we saved in the preprocessing step.\n",
    "\n",
    "Notice that we are creating a function that we can later reuse to create a training step using a different estimator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99e4850c-83d6-4f4e-a813-d5a3f4bb7486",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfcda131",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d92cac3d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23767878",
   "metadata": {},
   "source": [
    "## Session 5 - Custom Training Container\n",
    "\n",
    "This session creates a custom Docker image to train the model and have full control of the environment where the training script runs.\n",
    "\n",
    "For this example, we'll run the training script using [Keras 3](https://keras.io) with a [JAX](https://jax.readthedocs.io/en/latest/index.html) backend. Check [Adapting your own Docker container to work with SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-adapt-your-own.html) for more information about using your own Docker containers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877305d",
   "metadata": {},
   "source": [
    "### Step 1 - Preparing the Docker Image\n",
    "\n",
    "The first step is to copy the training script to a folder where we'll prepare the Docker image. We are going to reuse the training script we created before, since it's compatible with the latest version of Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57c2915c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af356028",
   "metadata": {},
   "source": [
    "Since we are creating a new Docker image, we need to install the libraries we need in the training container. We'll use a `requirements.txt` file to install these libraries. Notice that we are installing `jax` to run it as our backend.\n",
    "\n",
    "The `sagemaker-training` library contains the common functionality necessary to create a container compatible with SageMaker and its Python SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ffa9250",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fbed197",
   "metadata": {},
   "source": [
    "We can now create the Dockerfile containing the instructions to build the training image. Notice how this image will automatically run the `train.py` script when it starts.\n",
    "\n",
    "To use JAX as the backend for our model, we need to set the `KERAS_BACKEND` environment variable to `jax`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de5d473c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746dc0da",
   "metadata": {},
   "source": [
    "### Step 2 - Building the Docker Image\n",
    "\n",
    "We can now build the Docker image using the `docker build` command. We are going to define the name of this image using the `IMAGE_NAME` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e37a06ac",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56232bec",
   "metadata": {},
   "source": [
    "### Step 3 - Pushing Docker Image to ECR\n",
    "\n",
    "We can now push the Docker image to Amazon Elastic Container Registry (ECR). This is a fully-managed Docker container registry where we can manage Docker container images. This step is necessary to make the image available to SageMaker when running the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceede5e2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2413a387",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Training Step\n",
    "\n",
    "Let's now compute the name of the training image we'll use to run the Training Job.\n",
    "\n",
    "If we are running in `LOCAL_MODE`, we'll use the name of the image we built before (`IMAGE_NAME`). Otherwise, we'll use the name of the image we pushed to ECR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49d9ab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0be4eaf1",
   "metadata": {},
   "source": [
    "We can now create an [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) and a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) using the function we created before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4e17204",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3212693e",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86056197",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef68a77",
   "metadata": {},
   "source": [
    "## Session 6 - Tuning the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [step to tune the model](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning) using a Hyperparameter Tuning Job.\n",
    "\n",
    "<a href=\"images/tuning-step.png\" target=\"_blank\"> <img src=\"images/tuning-step.png\" alt=\"High-level overview of the Tuning Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96707b5",
   "metadata": {},
   "source": [
    "### Step 1 - Enabling Tuning\n",
    "\n",
    "Since we could use the Training of the Tuning Step to create a model, we'll define a constant to indicate which approach we want to run. Notice that the Tuning Step is not supported in Local Mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f367d0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5814e258-c633-4e9a-85c5-6ed0f168b503",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up a Tuning Step\n",
    "\n",
    "Let's now create a [Tuning Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning). This Tuning Step will create a SageMaker Hyperparameter Tuning Job in the background and use the training script to train different model variants and choose the best one. Check the [TuningStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "The Tuning Step requires a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) reference to configure the Hyperparameter Tuning Job.\n",
    "\n",
    "Here is the configuration that we'll use to find the best model:\n",
    "\n",
    "1. `objective_metric_name`: This is the name of the metric the tuner will use to determine the best model.\n",
    "2. `objective_type`: This is the objective of the tuner. It specifies whether it should minimize the metric or maximize it. In this example, since we are using the validation accuracy of the model, we want the objective to be \"Maximize.\" If we were using the loss of the model, we would set the objective to \"Minimize.\"\n",
    "3. `metric_definitions`: Defines how the tuner will determine the metric's value by looking at the output logs of the training process.\n",
    "\n",
    "The tuner expects the list of the hyperparameters you want to explore. You can use subclasses of the [Parameter](https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html#sagemaker.parameter.ParameterRange) class to specify different types of hyperparameters. This example explores different values for the `epochs` hyperparameter.\n",
    "\n",
    "Finally, you can control the number of jobs and how many of them will run in parallel using the following two arguments:\n",
    "\n",
    "-   `max_jobs`: Defines the maximum total number of training jobs to start for the hyperparameter tuning job.\n",
    "-   `max_parallel_jobs`: Defines the maximum number of parallel training jobs to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8c82750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c2abc2",
   "metadata": {},
   "source": [
    "We can now create the Tuning Step using the tuner we configured before. SageMaker will create a Hyperparameter Tuning Job in the background and use the training script to train different model variants and choose the best one.\n",
    "\n",
    "<a href=\"images/tuning-job.png\" target=\"_blank\"> <img src=\"images/tuning-job.png\" alt=\"High-level overview of SageMaker's Hyperparameter Tuning Jobs\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "038ff2e5-ed28-445b-bc03-4e996ec2286f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4babe38c-1682-42d2-8442-101d17aa89b5",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9799ab39-fcae-41f4-a68b-85ab71b3ba9a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21d40fe8-ba74-4c12-9555-d8ea33d1c8b4",
   "metadata": {},
   "source": [
    "## Session 7 - Evaluating the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to evaluate the model using the holdout set we created during the preprocessing step.\n",
    "\n",
    "<a href=\"images/evaluation-step.png\" target=\"_blank\"> <img src=\"images/evaluation-step.png\" alt=\"High-level overview of the Evaluation Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa9691-f49f-48af-b272-3d4d17563b01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1 - Creating the Evaluation Script\n",
    "\n",
    "We'll use a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) to execute the evaluation script.\n",
    "\n",
    "This script is responsible for loading the model we created and evaluating it on the test set. Before finishing, this script will generate an evaluation report of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb3406",
   "metadata": {},
   "source": [
    "We will store the script in a folder called `evaluation` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0590fcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2ccf926",
   "metadata": {},
   "source": [
    "We can now create the script inside the folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ee3ab26-afa5-4ceb-9f7a-005d5fdea646",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dcc79a0-adfd-4ce9-8580-5cd228c3c2d9",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a627a263",
   "metadata": {},
   "source": [
    "### Step 2 - Referencing the Model Assets\n",
    "\n",
    "One of the inputs to the evaluation step is the model coming from the Training or the Tuning step. We can use the `USE_TUNING_STEP` flag to determine whether we created the model using a Training Step or a Tuning Step.\n",
    "\n",
    "In case we are using the Tuning Step, we can use the [TuningStep.get_top_model_s3_uri()](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep.get_top_model_s3_uri) function to get the model assets from the top performing training job of the Hyperparameter Tuning Job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f19e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dc98283",
   "metadata": {},
   "source": [
    "### Step 3 - Mapping the Output to a Property File\n",
    "\n",
    "SageMaker supports mapping outputs from a Processing Step to property files. This is useful when we want to access a specific property from the pipeline.\n",
    "\n",
    "We'll map the evaluation report to a property file. Check [How to Build and Manage Property Files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f27b2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec1109a-6c26-4464-8338-94960729d212",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Evaluation Step\n",
    "\n",
    "To run the evaluation script, we will use a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) configured with a [TensorFlowProcessor](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks-tensorflow.html) because the script needs access to TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fdff07f",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a4dbc0e",
   "metadata": {},
   "source": [
    "We are now ready to define the [Processing Step](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) that will run the evaluation script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48139a07-5c8e-4bc6-b666-bf9531f7f520",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30413e8d",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21a1ab1f",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "031af83a",
   "metadata": {},
   "source": [
    "## Session 8 - Registering the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to [register the model](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-version.html) in the [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html).\n",
    "\n",
    "<a href=\"images/registration-step.png\" target=\"_blank\"> <img src=\"images/registration-step.png\" alt=\"High-level overview of the Registration Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1d882",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Model Package Group\n",
    "\n",
    "First, let's define the name of the group where we'll register the model. The Model Registry uses groups to organize the versions of a model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb70f907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40bcad3b",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Model\n",
    "\n",
    "Let's now create the model that we'll register in the Model Registry. The model we trained uses TensorFlow, so we can use the built-in [TensorFlowModel](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-model) class to create an instance of the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ca4cb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad0a532c",
   "metadata": {},
   "source": [
    "### Step 3 - Configuring Model Metrics\n",
    "\n",
    "When we register a model in the Model Registry, we can attach relevant metadata to it. We'll use the evaluation report we generated during the evaluation step to populate the [metrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) of this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c05a7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47bb3e51",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "We can use a [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model) to register the model. Check the [ModelStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.model_step.ModelStep) SageMaker's SDK documentation for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9773a4a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0276efc",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d09cc85",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3274db6",
   "metadata": {},
   "source": [
    "## Session 9 - Conditional Registration\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a condition to register the model only if its accuracy is above a predefined threshold.\n",
    "\n",
    "Here's a high-level overview of the Condition Step:\n",
    "\n",
    "<a href=\"images/condition-step.png\" target=\"_blank\"> <img src=\"images/condition-step.png\" alt=\"High-level overview of the Condition Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a51f95",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Accuracy Threshold\n",
    "\n",
    "Let's define a new [Pipeline Parameter](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) to specify the minimum accuracy that the model should reach for it to be registered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "745486b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c959c94",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up a Fail Step\n",
    "\n",
    "If the model's accuracy is not greater than or equal to our threshold, we will send the pipeline to a [Fail Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-fail) with the appropriate error message. Check the [FailStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.fail_step.FailStep) SageMaker's SDK documentation for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4431bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b47764f9",
   "metadata": {},
   "source": [
    "### Step 3 - Defining the Condition\n",
    "\n",
    "We can use a [ConditionGreaterThanOrEqualTo](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.conditions.ConditionGreaterThanOrEqualTo) condition to compare the model's accuracy with the threshold. Look at the [Conditions](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html#conditions) section in the documentation for more information about the types of supported conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bebeecab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c110f7-fe72-4db8-9d06-cfb9a0f2bfbd",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Condition Step\n",
    "\n",
    "Let's now use a [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) together with the evaluation report we generated to determine whether the model's accuracy is above the threshold:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36e2a2b1-6711-4266-95d8-d2aebd52e199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2309b8fa-f03e-4959-853f-dc2416f82bdd",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f70bcd33-b499-4e2b-953e-94d1ed96c10a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6176c6fd",
   "metadata": {},
   "source": [
    "## Session 10 - Serving the Model\n",
    "\n",
    "This session builds a simple [Flask](https://flask.palletsprojects.com/) application to serve the model.\n",
    "\n",
    "<a href=\"images/deploying-flask.png\" target=\"_blank\"> <img src=\"images/deploying-flask.png\" alt=\"High-level overview of deploying a model using a Flask wrapper\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Keep in mind that, while good for development and testing, this is not the best approach for production systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6e55d",
   "metadata": {},
   "source": [
    "### Step 1 - Retrieving List of Approved Models\n",
    "\n",
    "We want to serve the latest approved model from the Model Registry. We can use the [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html) API to get this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a67726d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca789bd2",
   "metadata": {},
   "source": [
    "### Step 2 - Downloading the Model\n",
    "\n",
    "Let's now download the model assets from the location specified in the Model Registry to your local environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2891178",
   "metadata": {},
   "source": [
    "We will store this model in a folder called `serving`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2e94adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "276c01cc",
   "metadata": {},
   "source": [
    "Let's now download the model assets into the folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd12fbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f02f2e42",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Serving Script\n",
    "\n",
    "Let's now write a simple Flask script to serve the model.\n",
    "\n",
    "When this application receives the first request, it will unpack and load the model into memory. From there, it will use the model to make predictions on the incoming requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c79a0e74",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0d4d828",
   "metadata": {},
   "source": [
    "### Step 4 - Running the Flask Application\n",
    "\n",
    "We can now run the Flask application to serve the model from a terminal using the following command:\n",
    "\n",
    "```bash\n",
    "$ flask --app program/code/serving/app.py --debug run --host=0.0.0.0 --port=4242\n",
    "```\n",
    "\n",
    "After the server is running, you can send a POST request to the server to get a prediction. Here is an example using the `curl` command:\n",
    "\n",
    "```bash\n",
    "$ curl --location --request POST 'http://localhost:4242/predict' \\\n",
    "    --header 'Content-Type: text/plain' \\\n",
    "    --data-raw '0.6569590202313976, -1.0813829646495108, 1.2097102831892812, 0.9226343641317372, 1.0, 0.0, 0.0'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a05e63",
   "metadata": {},
   "source": [
    "## Session 11 - Deploying the Model\n",
    "\n",
    "This session deploys the model from the Model Registry to an endpoint. We'll do it manually, using the SageMaker SDK. Check [Deploy to a SageMaker Endpoint](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#deploy-to-a-sagemaker-endpoint) for more information about deploying a model to an endpoint.\n",
    "\n",
    "<a href=\"images/deploying-model.png\" target=\"_blank\"> <img src=\"images/deploying-model.png\" alt=\"High-level overview of deploying a model to a SageMaker endpoint\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9b989",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Endpoint Name\n",
    "\n",
    "Let's start by defining the name of the endpoint where we'll deploy the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "befd5ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af752269",
   "metadata": {},
   "source": [
    "### Step 2 - Creating a Model Package\n",
    "\n",
    "To deploy a model using the SageMaker's Python SDK, we need to create a [Model Package](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.ModelPackage) using the ARN of the model from the Model Registry. Remember we got the ARN of the latest approved model in the previous section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dee516e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3119b48-2ddf-40b5-9ac0-680073a53d06",
   "metadata": {},
   "source": [
    "### Step 3 - Deploying the Model\n",
    "\n",
    "Let's now deploy the model to an endpoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf2ed9f",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c8852d5-818a-406c-944d-30bf6de90288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dd7a725",
   "metadata": {},
   "source": [
    "### Step 4 - Testing the Endpoint\n",
    "\n",
    "After deploying the model, we can test the endpoint to make sure it works.\n",
    "\n",
    "Each line of the payload we'll send to the endpoint contains the information of a penguin. Notice the model expects data that's already transformed. We can't provide the original data from our dataset because the model we registered will not work with it.\n",
    "\n",
    "The endpoint will return the predictions for each of these lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba7da291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bcfffa-0ba6-4ad8-8b4f-1ea19b35a22f",
   "metadata": {},
   "source": [
    "Let's send the payload to the endpoint and print its response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0817a25e-8224-4911-830b-d659e7458b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ab1884",
   "metadata": {},
   "source": [
    "## Session 12 - Deploying From the Pipeline\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to automatically deploy the model to an endpoint.\n",
    "\n",
    "We'll use a [Lambda Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-lambda) to create an endpoint and deploy the model.\n",
    "\n",
    "Here's a high-level overview of the Deploy Step:\n",
    "\n",
    "<a href=\"images/deploy-step.png\" target=\"_blank\"> <img src=\"images/deploy-step.png\" alt=\"High-level overview of the Deploy Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb6753",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Data Capture Settings\n",
    "\n",
    "We want to enable [Data Capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html) as part of the endpoint configuration. With Data Capture we can record the inputs and outputs of the endpoint to use them later for monitoring the model. We need to configuration settings to enable Data Capture:\n",
    "\n",
    "-   `DATA_CAPTURE_PERCENTAGE`: Represents the percentage of traffic that we want to capture.\n",
    "-   `DATA_CAPTURE_DESTINATION`: Specifies the S3 location where we want to store the captured data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1dbadb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5686ba99",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up the Lambda Function\n",
    "\n",
    "Let's start by writing a Lambda function that takes the model information and deploys it to an endpoint.\n",
    "\n",
    "There are three components that make up a SageMaker endpoint:\n",
    "\n",
    "<a href=\"images/endpoint.png\" target=\"_blank\"> <img src=\"images/endpoint.png\" alt=\"An overview of the three components of an Endpoint\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48c7bd",
   "metadata": {},
   "source": [
    "We'll store the code of the function in a folder called `lambda`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac7630ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "811f35b1",
   "metadata": {},
   "source": [
    "Let's now write the code of the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44b651af",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b601027a",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up Lambda Permissions\n",
    "\n",
    "We need to ensure our Lambda function has permission to interact with SageMaker, so let's create a new role with the appropriate permissions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "200d0370",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f81794",
   "metadata": {},
   "source": [
    "### Step 4 - Creating the Lambda Function\n",
    "\n",
    "Let's now create the Lambda function in AWS. We'll pass the configuration settings we defined before as environment variables to the Lambda function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a742974",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b46c806e",
   "metadata": {},
   "source": [
    "### Step 5 - Setting up the Lambda Step\n",
    "\n",
    "We can now define the [Lambda Step](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) that will run the function to deploy the model. We'll do this in a function that we can reuse later.\n",
    "\n",
    "This step will send the model package ARN we want to deploy to the Lambda function as an input parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f86b997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40f2b11e",
   "metadata": {},
   "source": [
    "### Step 6 - Modifying the Condition Step\n",
    "\n",
    "We need to modify the [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) to include the new deployment step. If the condition succeeds, we will register and deploy the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5cc3e44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1951be04",
   "metadata": {},
   "source": [
    "### Step 7 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3d86577a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbddc94b",
   "metadata": {},
   "source": [
    "### Step 8 - Testing the Endpoint\n",
    "\n",
    "Let's test the endpoint to make sure it works.\n",
    "\n",
    "The `wait_for_endpoint` function will wait until the endpoint is ready to receive requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1dd5bb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c31653",
   "metadata": {},
   "source": [
    "## Session 13 - Deploying From an Event\n",
    "\n",
    "This session modifies the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) to register the model with `PendingManualApproval` status and deploys it whenever its status changes to `Approved`.\n",
    "\n",
    "<a href=\"images/deploying-from-event.png\" target=\"_blank\"> <img src=\"images/deploying-from-event.png\" alt=\"High-level overview of deploying a model using EventBridge\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We will use [Amazon EventBridge](https://aws.amazon.com/pm/eventbridge/) to trigger a Lambda function that will deploy the model whenever its status changes from \"PendingManualApproval\" to \"Approved.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ad7d3",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Model Package Group\n",
    "\n",
    "We need to define the name of a new group where we'll register models with `PendingManualApproval` status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96751e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbdfb284",
   "metadata": {},
   "source": [
    "### Step 2 - Setting Up EventBridge\n",
    "\n",
    "We can now create an EventBridge rule that triggers the deployment process whenever a model approval status becomes `Approved`. To do this, let's define the event pattern that will trigger the deployment process. Check [Model package state change](https://docs.aws.amazon.com/sagemaker/latest/dg/automating-sagemaker-with-eventbridge.html#eventbridge-model-package) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ee4b9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "173c4908",
   "metadata": {},
   "source": [
    "Let's now create the EventBridge rule:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63f294bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "736c2148",
   "metadata": {},
   "source": [
    "Now, we need to define the target of the rule. The target will trigger whenever the rule matches an event. In this case, we want to trigger the Lambda function we created before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9985bd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c22f63b",
   "metadata": {},
   "source": [
    "### Step 3 - Configuring the Lambda Permissions\n",
    "\n",
    "Finally, we need to give the Lambda function permissions to be triggered by the EventBridge rule:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "32302639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1a12be",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "We need to modify the [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model) to register the model using `PendingManualApproval` status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18adeb93",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce34e825",
   "metadata": {},
   "source": [
    "### Step 5 - Modifying the Condition Step\n",
    "\n",
    "Let's modify the [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) to include the new registration step. If the condition succeeds, we will register the model with `PendingManualApproval` status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fafb5514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "070a5a5d",
   "metadata": {},
   "source": [
    "### Step 6 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b95c22b2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adcf1f02",
   "metadata": {},
   "source": [
    "## Session 14 - Building an Inference Pipeline\n",
    "\n",
    "This session creates an inference pipeline to control the data that goes in and comes out of the endpoint.\n",
    "\n",
    "Deploying the model we trained directly to an endpoint doesn't lets us control the data that goes in and comes out of the endpoint. The TensorFlow model we trained requires transformed data, which makes it useless to other applications:\n",
    "\n",
    "<a href=\"images/basic-model.png\" target=\"_blank\"> <img src=\"images/basic-model.png\" alt=\"Basic Model\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "To fix this, we can create an Inference Pipeline using SageMaker to control the data that goes in and comes out of the endpoint.\n",
    "\n",
    "Our inference pipeline will have three components:\n",
    "\n",
    "1. A preprocessing component that will transform the input data into the format the model expects.\n",
    "2. The TensorFlow model.\n",
    "3. A postprocessing component that will transform the output of the model into a human-readable format.\n",
    "\n",
    "<a href=\"images/inference-pipeline.png\" target=\"_blank\"> <img src=\"images/inference-pipeline.png\" alt=\"Inference pipeline\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We want our endpoint to handle unprocessed data in CSV and JSON format and return the penguin's species. Here is an example of the payload input we want the endpoint to support:\n",
    "\n",
    "```{json}\n",
    "{\n",
    "    \"island\": \"Biscoe\",\n",
    "    \"culmen_length_mm\": 48.6,\n",
    "    \"culmen_depth_mm\": 16.0,\n",
    "    \"flipper_length_mm\": 230.0,\n",
    "    \"body_mass_g\": 5800.0\n",
    "}\n",
    "```\n",
    "\n",
    "And here is an example of the output we'd like to get from the endpoint:\n",
    "\n",
    "```{json}\n",
    "{\n",
    "    \"prediction\": \"Adelie\",\n",
    "    \"confidence\": 0.802672\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b597447",
   "metadata": {},
   "source": [
    "### Step 1 - Creating the Preprocessing Script\n",
    "\n",
    "The first component of our inference pipeline will transform the input data into the format the model expects.\n",
    "\n",
    "We'll use the Scikit-Learn transformer we saved when we split and transformed the data. To deploy this component as part of an inference pipeline, we need to write a script that loads the transformer, uses it to modify the input data, and returns the output in the format the TensorFlow model expects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1de322",
   "metadata": {},
   "source": [
    "We'll store the scripts of every component in a folder called `pipeline` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a1f25973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b1cc77f",
   "metadata": {},
   "source": [
    "Let's now create the script for the preprocessing component:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c480ae02",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b582ba8b",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34721e63",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c12017c",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Postprocessing Script\n",
    "\n",
    "The final component of our inference pipeline will transform the output from the model into a human-readable format.\n",
    "\n",
    "We'll use the Scikit-Learn target transformer we saved when we split and transformed the data. To deploy this component as part of an inference pipeline, we need to write a script that loads the transformer, uses it to modify the output from the model, and returns a human-readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d23798aa",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67725bb1",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "965a6be5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29abbf51",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up the Inference Pipeline\n",
    "\n",
    "We can now create a [PipelineModel](https://sagemaker.readthedocs.io/en/stable/api/inference/pipeline.html#sagemaker.pipeline.PipelineModel) to define our inference pipeline.\n",
    "\n",
    "We'll use the model we generated in the Split and Transform step as the input to the first and last components of the inference pipeline. This `model.tar.gz` file contains the two transformers we need to preprocess and postprocess the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf32c18",
   "metadata": {},
   "source": [
    "Let's create a variable with the URI to this file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82dafcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6ab6b5b",
   "metadata": {},
   "source": [
    "Here is the first component of the inference pipeline. It will preprocess the data before sending it to the TensorFlow model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c7dda7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e71a20b",
   "metadata": {},
   "source": [
    "Here is the last component of the inference pipeline. It will postprocess the output from the TensorFlow model before sending it back to the user:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c31090e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba11abe",
   "metadata": {},
   "source": [
    "We can now create the inference pipeline using the three models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fa95ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a9d7393",
   "metadata": {},
   "source": [
    "### Step 4 - Configuring the Model Package Group\n",
    "\n",
    "Let's define a new package group to register the Pipeline Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c052332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55f7b2df",
   "metadata": {},
   "source": [
    "### Step 5 - Registering the Model\n",
    "\n",
    "We'll modify the registration step to register the Pipeline Model in the Model Registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3cb0ce9e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55883c31",
   "metadata": {},
   "source": [
    "### Step 6 - Modifying the Deploy Step\n",
    "\n",
    "Let's now modify the [LambdaStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) to use the updated Registration Step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ec7b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c00a4ebb-fb21-4935-9d7b-9500e47e07f9",
   "metadata": {},
   "source": [
    "### Step 7 - Modifying the Condition Step\n",
    "\n",
    "Since we modified the Registration Step, we also need to modify the Condition Step to use the new registration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9712905-9fe3-4148-ae6d-05b0a48e742e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0730a388",
   "metadata": {},
   "source": [
    "### Step 8 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bad9f51d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dfe7356-53e8-4ac1-9a7f-3bd51bb739a5",
   "metadata": {},
   "source": [
    "### Step 9 - Testing the Endpoint\n",
    "\n",
    "Let's now test the endpoint. Notice that we can now send the raw data to the endpoint, and it will return the penguin's species in a human-readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3cc966fb-b611-417f-a8b8-0c5d2f95252c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83fd85c2",
   "metadata": {},
   "source": [
    "We can also test the endpoint by sending a JSON payload. Notice how you can use a deserealizer to automatically decode the response from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce3d33f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "697dce40",
   "metadata": {},
   "source": [
    "And now let's send the same payload but return the prediction in CSV format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "240aaff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a3b50c",
   "metadata": {},
   "source": [
    "## Session 15 - Custom Inference Script\n",
    "\n",
    "This session creates a custom inference script to control the inference process in the SageMaker endpoint. This is an alternative to creating an inference pipeline to preprocess and postprocess the data that comes in and out of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527690f",
   "metadata": {},
   "source": [
    "### Step 1 - Creating the Inference Script\n",
    "\n",
    "Let's create a script where we'll manage the inference process in the endpoint.\n",
    "\n",
    "We'll' include this code as part of the model assets to control the inference process on the SageMaker endpoint. SageMaker will automatically call the `handler()` function for every request to the endpoint. Check [How to implement the pre- and/or post-processing handler(s)](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html#how-to-implement-the-pre-and-or-post-processing-handler-s) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b90af",
   "metadata": {},
   "source": [
    "We can now create the script inside the folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "97b3cd80",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19fbf40d",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91786cc7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57430168",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Model\n",
    "\n",
    "We can now create a new [TensorFlowModel](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-model) including the `inference.py` file.\n",
    "\n",
    "SageMaker triggers a repack operation whenever we specify the `source_dir` attribute in a model. We want that attribute to point to the local folder containing the `inference.py` file. SageMaker will automatically modify the original `model.tar.gz` package to include a `/code` folder containing the file.\n",
    "\n",
    "Since we need access to Scikit-Learn in our script, we can include a `requirements.txt` file in the same location where the `inference.py` script is, and SageMaker will install everything in it.\n",
    "\n",
    "To repack the model assets, SageMaker will automatically include a new step in the pipeline right before registering the model.\n",
    "\n",
    "Here is what the new `model.tar.gz` package will look like:\n",
    "\n",
    "```\n",
    "model/\n",
    "    |--[model_version_number]\n",
    "        |--assets/\n",
    "        |--variables/\n",
    "        |--saved_model.pb\n",
    "    |--features.joblib\n",
    "    |--target.joblib\n",
    "code/\n",
    "    |--inference.py\n",
    "    |--requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3cfdd3",
   "metadata": {},
   "source": [
    "Let's create a `requirements.txt` file with all the libraries we want SageMaker to install in the inference container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "603cb8f5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f9c7a0d",
   "metadata": {},
   "source": [
    "We can now create the model using the `inference.py` script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b5015c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74ce15c7",
   "metadata": {},
   "source": [
    "### Step 3 - Configuring the Model Package Group\n",
    "\n",
    "Let's define a new group where we'll register the model using the custom `inference.py` script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7ee3cdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a98b5c0a",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "We can now modify the registration step to register the custom model in the Model Registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "21fb3e2c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9293b0",
   "metadata": {},
   "source": [
    "### Step 5 - Modifying the Deploy Step\n",
    "\n",
    "Let's now modify the [LambdaStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) to use the updated Registration Step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9e8162b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd1812e7",
   "metadata": {},
   "source": [
    "### Step 6 - Modifying the Condition Step\n",
    "\n",
    "Since we modified the Registration Step, we also need to modify the Condition Step to use the new registration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "849b379f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "671a5efb",
   "metadata": {},
   "source": [
    "### Step 7 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f64921ee",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a6f02a4",
   "metadata": {},
   "source": [
    "### Step 8 - Testing the Endpoint\n",
    "\n",
    "Let's test the endpoint to make sure it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1d63ce59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1c7a3a1",
   "metadata": {},
   "source": [
    "## Session 16 - Data Quality Baseline\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to compute a baseline for the data the endpoint expects.\n",
    "\n",
    "This step will compute statistics and constraints from the data. We'll' later use this information as the baseline to detect data drift and other data quality issues.\n",
    "\n",
    "<a href=\"images/data-quality-baseline.png\" target=\"_blank\"> <img src=\"images/data-quality-baseline.png\" alt=\"Data Quality Baseline\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Check [Monitor data quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html) for more information about monitoring data quality in SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb16c8",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Baseline Location\n",
    "\n",
    "Let's start by defining the location where SageMaker will store the baseline data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f4747fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaae1030",
   "metadata": {},
   "source": [
    "### Step 2 - Generating Data Quality Baseline\n",
    "\n",
    "Let's configure a [QualityCheck Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to compute the general statistics of the data we used to build our model.\n",
    "\n",
    "We can configure the instance that will run the quality check using the [CheckJobConfig](https://sagemaker.readthedocs.io/en/v2.73.0/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.check_job_config.CheckJobConfig) class, and we can use the `DataQualityCheckConfig` class to configure the job.\n",
    "\n",
    "We are running this step with the following configuration:\n",
    "\n",
    "-   `skip_check = True`: This parameter controls whether the step should skip checking the data against a previous baseline. Since we want to generate the baseline for the first time, we set it to `True`. After running the pipeline once to generate the baseline, we can set this parameter to `False` to ensure any new data follows the same distribution as the baseline.\n",
    "\n",
    "-   `register_new_baseline = True`: This parameter controls whether the new calculated baseline will be registered in the Model Registry.\n",
    "\n",
    "For more information about these configuration parameters, check [Baseline calculation and registration](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3fc728fa",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebac2646",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up Model Metrics\n",
    "\n",
    "We can configure a new set of [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) using the results of the Quality Step. Check [Baseline and model version lifecycle and evolution with SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html#pipelines-quality-clarify-baseline-evolution) for an explanation of how SageMaker uses the `DriftCheckBaselines`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d5d8133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79ce8965",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "Let's modify the registration step to use the new metrics and the drift baseline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fc5c4325",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81802ef",
   "metadata": {},
   "source": [
    "### Step 5 - Modifying the Condition Step\n",
    "\n",
    "Since we modified the Registration Step, we also need to modify the Condition Step to use the new registration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "be9d6de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eea28519",
   "metadata": {},
   "source": [
    "### Step 6 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fb9b8d1e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88501998",
   "metadata": {},
   "source": [
    "### Step 7 - Checking Constraints and Statistics\n",
    "\n",
    "Our pipeline generated data baseline statistics and constraints. We can take a look at what these values look like by downloading them from S3. You need to wait for the pipeline to finish running before these files are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4a917",
   "metadata": {},
   "source": [
    "Here are the data quality statistics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c2b95d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8436b273",
   "metadata": {},
   "source": [
    "Here are the data quality constraints:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "63908598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9631cf7b",
   "metadata": {},
   "source": [
    "## Session 17 - Model Quality Baseline\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [QualityCheck Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to compute a baseline for the model performance.\n",
    "\n",
    "This step will compute the baseline metrics we will later use as the baseline to detect model drift.\n",
    "\n",
    "To create a baseline to compare the model performance, we must create predictions for the test set and compare the model's metrics with the model performance on production data. We can do this by running a [Batch Transform Job](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to predict every sample from the test set. We can use a [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) as part of the pipeline to run this job.\n",
    "\n",
    "<a href=\"images/model-quality-baseline.png\" target=\"_blank\"> <img src=\"images/model-quality-baseline.png\" alt=\"Model Quality Baseline\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Check [Monitor model quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html) for more information about monitoring model quality in SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df4f23",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Baseline Location\n",
    "\n",
    "Let's start by defining the location where SageMaker will store the baseline data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "69e115c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e0a633b",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Model\n",
    "\n",
    "The [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) requires a model to generate predictions, so we need a [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model) that creates a model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f93f2751",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac142cc0",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up the Transform Step\n",
    "\n",
    "We are going to use a [Batch Transform Job](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to generate predictions for every sample from the test set.\n",
    "\n",
    "This Batch Transform Job will run every sample from the training dataset through the model so we can compute the baseline metrics. Check [Run a Batch Transform Job](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#run-a-batch-transform-job) for more information about running a Batch Transform Job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227e304",
   "metadata": {},
   "source": [
    "Let's start by configuring a [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) instance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2a530d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63bfde28",
   "metadata": {},
   "source": [
    "We can now set up the [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) using the [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) we configured before.\n",
    "\n",
    "Notice the following:\n",
    "\n",
    "-   We'll generate predictions for the baseline test data that we generated when we split and transformed the data. This baseline is the same data we used to test the model, but it's in raw format.\n",
    "-   The output of this Batch Transform Job will have two fields. The first one will be the ground truth label, and the second one will be the prediction of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "653c6ec8",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8956e12b",
   "metadata": {},
   "source": [
    "### Step 4 - Generating Model Quality Baseline\n",
    "\n",
    "Let's now configure the [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and feed it the data we generated in the Transform Step. This step will automatically compute the performance metrics of the model on the test set.\n",
    "\n",
    "We are running this step with the following configuration:\n",
    "\n",
    "-   `skip_check = True`: This parameter controls whether the step should skip checking the data against a previous baseline. Since we want to generate the baseline for the first time, we set it to `True`. After running the pipeline once to generate the baseline, we can set this parameter to `False` to ensure any new data follows the same distribution as the baseline.\n",
    "\n",
    "-   `register_new_baseline = True`: This parameter controls whether the new calculated baseline will be registered in the Model Registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b50a9ed5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c1f847",
   "metadata": {},
   "source": [
    "### Step 5 - Setting up Model Metrics\n",
    "\n",
    "We can configure a new set of [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) using the results of the Quality Step. Check [Baseline and model version lifecycle and evolution with SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html#pipelines-quality-clarify-baseline-evolution) for an explanation of how SageMaker uses the `DriftCheckBaselines`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3aecc022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2ca87f",
   "metadata": {},
   "source": [
    "### Step 6 - Registering the Model\n",
    "\n",
    "Let's modify the registration step to use the new metrics and the drift baseline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "20154a1a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a725d23c",
   "metadata": {},
   "source": [
    "### Step 7 - Modifying the Condition Step\n",
    "\n",
    "We need to modify the Condition Step to include the new Registration Step and the Transform and Quality Check Steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd84e567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f7d9f1f",
   "metadata": {},
   "source": [
    "### Step 8 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c244e206",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97fdc363",
   "metadata": {},
   "source": [
    "### Step 9 - Checking Constraints\n",
    "\n",
    "Our pipeline generated model baseline constraints. We can take a look at what these values look like by downloading them from S3. You need to wait for the pipeline to finish running before the file is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dc31aa28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dd9b8b7",
   "metadata": {},
   "source": [
    "## Session 18 - Data Monitoring\n",
    "\n",
    "This session creates a Monitoring Job to monitor the quality of the data received by the endpoint. This schedule will run periodically and check the data that goes into the endpoint against the baseline we generated before.\n",
    "\n",
    "Check [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html) for an explanation of how to use SageMaker's Model Monitoring functionality. [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) is a much more extensive guide to monitoring in Amazon SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732149d",
   "metadata": {},
   "source": [
    "### Step 1 - Deploying the Model\n",
    "\n",
    "Let's deploy the latest approved model to an endpoint.\n",
    "\n",
    "Since we need to do the same later, we can create a function to deploy the model. Notice how we need to enable Data Capture to monitor the data that goes in and out of the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "57cc8903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21872e7d",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4966c9c2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "468c73dd",
   "metadata": {},
   "source": [
    "### Step 2 - Generating Fake Traffic\n",
    "\n",
    "To test the monitoring functionality, we need to generate traffic to the endpoint. To generate traffic, we will send every sample from the dataset to the endpoint to simulate real prediction requests:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cea757af",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "947c4408",
   "metadata": {},
   "source": [
    "We can check the location where the endpoint stores the captured data, download a file, and display its content. It may take a few minutes for the first few files to show up in S3.\n",
    "\n",
    "These files contain the data captured by the endpoint in a SageMaker-specific JSON-line format. Each inference request is captured in a single line in the `jsonl` file. The line contains both the input and output merged together:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "caee992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5e9c62b",
   "metadata": {},
   "source": [
    "### Step 3 - Creating Custom Preprocessing Script\n",
    "\n",
    "SageMaker looks for violations in the data captured by the endpoint. By default, it combines the input data with the endpoint output and compares the result with the baseline we generated before. If we let SageMaker do this, we will get a few violations, for example an \"extra column check\" violation because the field `confidence` doesn't exist in the baseline data.\n",
    "\n",
    "We can fix these violations by creating a preprocessing script configuring the data we want the monitoring job to use. Check [Preprocessing and Postprocessing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html) for more information about how to configure these scripts.\n",
    "\n",
    "We'll store the script in a folder called `monitoring`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7b48cd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058ddea2",
   "metadata": {},
   "source": [
    "We can now define the preprocessing script. Notice that this script will return a JSON object with a name for each feature and their value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0114a817",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12c1b8df",
   "metadata": {},
   "source": [
    "### Step 4 - Uploading Preprocessing Script\n",
    "\n",
    "The monitoring schedule expects an S3 location pointing to the preprocessing script. Let's upload the script to the default bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "21240214",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eefd191e",
   "metadata": {},
   "source": [
    "### Step 5 - Creating Monitoring Schedule\n",
    "\n",
    "We can now set up the Data Quality Monitoring Job using the [DefaultModelMonitor](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.DefaultModelMonitor) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b9df3d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02af1681",
   "metadata": {},
   "source": [
    "Let's now create the monitoring schedule. Notice how we specify the `record_preprocessor_script` using the S3 location where we uploaded our script.\n",
    "\n",
    "We are going to set up the monitoring schedule to run every hour. Keep in mind that SageMaker has a buffer period of 20 minutes to schedule an execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7320924",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c2b3fe69",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3e38659",
   "metadata": {},
   "source": [
    "### Step 6 - Checking Violations\n",
    "\n",
    "After the monitoring schedule runs for the first time, we can check the results of the last execution. If the job completed successfully, we can check if there are any violations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5cedff08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e9faf0",
   "metadata": {},
   "source": [
    "### Step 7 - Deleting Monitoring Schedule\n",
    "\n",
    "Once we are done with it, we can delete the Data Monitoring schedule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7ff8bfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4ec9a8b",
   "metadata": {},
   "source": [
    "## Session 19 - Model Monitoring\n",
    "\n",
    "This session creates a Monitoring Job to monitor the quality of the model outputs. This schedule will run periodically and check the data that goes into the endpoint against the baseline we generated before.\n",
    "\n",
    "Check [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html) for an explanation of how to use SageMaker's Model Monitoring functionality. [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) is a much more extensive guide to monitoring in Amazon SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ff7f2",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Ground Truth Location\n",
    "\n",
    "Let's start by defining the location where SageMaker will store the ground-truth generated by labeling the data received by the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5ddca53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c05a19",
   "metadata": {},
   "source": [
    "### Step 2 - Deploying the Model\n",
    "\n",
    "Let's deploy the latest approved model to an endpoint.\n",
    "\n",
    "Here, we can reuse the function we created before to deploy the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab3618",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c2089ba4",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8cd4962",
   "metadata": {},
   "source": [
    "### Step 3 - Generating Fake Traffic\n",
    "\n",
    "To test the monitoring functionality, we need to generate traffic to the endpoint. We can use the function we created before to generate fake traffic to the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c4545041",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c0ff1ce",
   "metadata": {},
   "source": [
    "We can check the location where the endpoint stores the captured data, download a file, and display its content. It may take a few minutes for the first few files to show up in S3.\n",
    "\n",
    "These files contain the data captured by the endpoint in a SageMaker-specific JSON-line format. Each inference request is captured in a single line in the `jsonl` file. The line contains both the input and output merged together:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "49bc662a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "421ec421",
   "metadata": {},
   "source": [
    "### Step 4 - Generating Fake Labels\n",
    "\n",
    "To test the performance of the model, we need to label the samples captured by the endpoint. We can simulate the labeling process by generating a random label for every sample. Check [Ingest Ground Truth Labels and Merge Them With Predictions](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html) for more information about this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a4a32d8c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19a4a9cf",
   "metadata": {},
   "source": [
    "### Step 5 - Creating Monitoring Schedule\n",
    "\n",
    "To set up a Model Quality Monitoring Job, we can use the [ModelQualityMonitor](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelQualityMonitor) class.\n",
    "\n",
    "Check [Amazon SageMaker Model Quality Monitor](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.html) for a complete tutorial on how to run a Model Monitoring Job in SageMaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "54762759",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "939c392f",
   "metadata": {},
   "source": [
    "Let's now create the monitoring schedule. The [EndpointInput](https://sagemaker.readthedocs.io/en/v2.24.2/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.EndpointInput) instance configures the attribute the monitoring job should use to determine the prediction from the model.\n",
    "\n",
    "We are going to set up the monitoring schedule to run every hour. Keep in mind that SageMaker has a buffer period of 20 minutes to schedule an execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d28eb3",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9665c61a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aab1e110",
   "metadata": {},
   "source": [
    "### Step 6 - Checking Violations\n",
    "\n",
    "After the monitoring schedule runs for the first time, we can check the results of the last execution. If the job completed successfully, we can check if there are any violations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "34ba56d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d403f00",
   "metadata": {},
   "source": [
    "### Step 7 - Deleting Monitoring Schedule\n",
    "\n",
    "Once we are done with it, we can delete the Data Monitoring schedule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7f250115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae348ea3",
   "metadata": {},
   "source": [
    "## Session 20 - Shadow Deployments\n",
    "\n",
    "This session configures an endpoint running a production and a shadow variant. Check [Safely validate models in production](https://docs.aws.amazon.com/sagemaker/latest/dg/model-validation.html) for more information.\n",
    "\n",
    "<a href=\"images/shadow-deployment.png\" target=\"_blank\"> <img src=\"images/shadow-deployment.png\" alt=\"Shadow Deployment\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19314442",
   "metadata": {},
   "source": [
    "### Step 1 - Getting The Latest Models\n",
    "\n",
    "We want to deploy the two latest approved models from the Model Registry to the same endpoint. The latest version of the model will act as the Shadow variant, and the previous version will act as the Production variant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d322d415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "015b7995",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Models\n",
    "\n",
    "We want to deploy the two packages to a new endpoint. We'll use the boto3 API to deploy these models.\n",
    "\n",
    "Let's start by creating the SageMaker Models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6c8aea09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b29826d",
   "metadata": {},
   "source": [
    "Let's now create the Production model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dd20b354",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af41dac0",
   "metadata": {},
   "source": [
    "And now we can create the second model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d2024f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1215beb",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Endpoint Configuration\n",
    "\n",
    "We can now create the Endpoint Configuration using the two models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d35d1",
   "metadata": {},
   "source": [
    "Let's define the location where SageMaker will output the information captured by the Shadow variant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "85769b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c97fe3bf",
   "metadata": {},
   "source": [
    "We can create the Endpoint Configuration now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "969df4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d8baad3",
   "metadata": {},
   "source": [
    "### Step 4 - Creating the Endpoint\n",
    "\n",
    "Finally, we can create the Endpoint using the Endpoint Configuration we created before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb879c",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "33e8d886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "248702a3",
   "metadata": {},
   "source": [
    "### Step 5 - Generating Traffic\n",
    "\n",
    "Let's generate some traffic to the endpoint so we can test the Shadow variant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "069afdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04a5f044",
   "metadata": {},
   "source": [
    "### Step 6 - Checking Captured Data\n",
    "\n",
    "Let's check the location where the endpoint stores the captured data, download a file, and display its content. It may take a few minutes for the first few files to show up in S3.\n",
    "\n",
    "The endpoint will capture the data for both the Production and the Shadow variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9ffadf06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8535163",
   "metadata": {},
   "source": [
    "### Step 7 - Deleting the Endpoint\n",
    "\n",
    "Let's now delete the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2ee1ce12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff8f99c1",
   "metadata": {},
   "source": [
    "## Running the Pipeline\n",
    "\n",
    "We can run any of the pipelines we defined before by enabling the cell below and specifying the pipeline we want to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc01c152",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "59d1e634",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28f5d383-fcd7-454c-bbd6-ce4ce7b2104a",
   "metadata": {},
   "source": [
    "## Deleting the Endpoint\n",
    "\n",
    "After testing the endpoint, we need to ensure we delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6b32c3a4-312e-473c-a217-33606f77d1e9",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd7313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:325223348818:studio-lifecycle-config/packages",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
